{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some examples of some best practices to look out for when cleaning data.\n",
    "I'll use some DataFrames that are made up. But if you want to see how this can be handled, I also have a repository on how to use Reddit API, clean and analyze the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Examples of how to clean data\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "       Product  Price  Quantity\n",
      "0  Solar Panel  250.0      10.0\n",
      "1     Inverter  500.0       5.0\n",
      "2      Battery    NaN       8.0\n",
      "3  Solar Panel  300.0       NaN\n",
      "4          NaN  450.0       7.0\n",
      "\n",
      "DataFrame after dropping rows with missing values:\n",
      "       Product  Price  Quantity\n",
      "0  Solar Panel  250.0      10.0\n",
      "1     Inverter  500.0       5.0\n",
      "\n",
      "DataFrame after imputing missing values:\n",
      "       Product  Price  Quantity\n",
      "0  Solar Panel  250.0      10.0\n",
      "1     Inverter  500.0       5.0\n",
      "2      Battery  375.0       8.0\n",
      "3  Solar Panel  300.0       7.5\n",
      "4      Unknown  450.0       7.0\n"
     ]
    }
   ],
   "source": [
    "# Sample DataFrame\n",
    "data = {\n",
    "    'Product': ['Solar Panel', 'Inverter', 'Battery', 'Solar Panel', np.nan],\n",
    "    'Price': [250, 500, np.nan, 300, 450],\n",
    "    'Quantity': [10, 5, 8, np.nan, 7]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Handling Missing Values\n",
    "\n",
    "# 1. Removing rows with any missing values\n",
    "df_cleaned = df.dropna()\n",
    "print(\"\\nDataFrame after dropping rows with missing values:\")\n",
    "print(df_cleaned)\n",
    "\n",
    "# 2. Imputing missing values\n",
    "df_imputed = df.copy()\n",
    "df_imputed['Product'].fillna('Unknown', inplace=True)\n",
    "df_imputed['Price'].fillna(df_imputed['Price'].mean(), inplace=True)\n",
    "df_imputed['Quantity'].fillna(df_imputed['Quantity'].median(), inplace=True)\n",
    "print(\"\\nDataFrame after imputing missing values:\")\n",
    "print(df_imputed)\n",
    "\n",
    "# There are different ways to handle missing values, such as using the mean, median, mode, or a constant value to fill in the missing values.\n",
    "# You can also use more advanced techniques like interpolation or machine learning algorithms to impute missing values.\n",
    "# It's important to consider the nature of the data and the impact of different imputation methods on the analysis.\n",
    "# In some cases, it may be appropriate to drop rows or columns with missing values if they are not critical to the analysis.\n",
    "# Always carefully evaluate the implications of handling missing values in your data.\n",
    "# And also make sure to let the reader(either of the code or others on your project team) know how you handled missing values in your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to Handle Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with Duplicates:\n",
      "   OrderID      Product  Price  Quantity\n",
      "0      101  Solar Panel    250        10\n",
      "1      102     Inverter    500         5\n",
      "2      103      Battery    300         8\n",
      "3      101  Solar Panel    250        10\n",
      "4      104      Battery    300         8\n",
      "\n",
      "DataFrame after removing duplicates:\n",
      "   OrderID      Product  Price  Quantity\n",
      "0      101  Solar Panel    250        10\n",
      "1      102     Inverter    500         5\n",
      "2      103      Battery    300         8\n",
      "4      104      Battery    300         8\n"
     ]
    }
   ],
   "source": [
    "# How to Handle Duplicates\n",
    "# Sample DataFrame with duplicates\n",
    "data = {\n",
    "    'OrderID': [101, 102, 103, 101, 104],\n",
    "    'Product': ['Solar Panel', 'Inverter', 'Battery', 'Solar Panel', 'Battery'],\n",
    "    'Price': [250, 500, 300, 250, 300],\n",
    "    'Quantity': [10, 5, 8, 10, 8]\n",
    "}\n",
    "df_duplicates = pd.DataFrame(data)\n",
    "\n",
    "print(\"DataFrame with Duplicates:\")\n",
    "print(df_duplicates)\n",
    "\n",
    "# Removing duplicate rows\n",
    "df_no_duplicates = df_duplicates.drop_duplicates()\n",
    "print(\"\\nDataFrame after removing duplicates:\")\n",
    "print(df_no_duplicates)\n",
    "\n",
    "# In some cases, duplicate rows may be valid and should not be removed.\n",
    "# It's important to carefully consider the context of the data and the impact of removing duplicates on the analysis.\n",
    "# Again, it's important to communicate how duplicates were handled in your analysis to ensure transparency and reproducibility.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to Handle different or Incorrect Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with Incorrect Data Types:\n",
      "OrderID     object\n",
      "Product     object\n",
      "Price       object\n",
      "Quantity    object\n",
      "dtype: object\n",
      "\n",
      "DataFrame after Correcting Data Types:\n",
      "OrderID       int64\n",
      "Product      object\n",
      "Price       float64\n",
      "Quantity      int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# How to Handle Incorrect Data Types\n",
    "# Sample DataFrame with incorrect data types\n",
    "data = {\n",
    "    'OrderID': ['101', '102', '103', '104'],\n",
    "    'Product': ['Solar Panel', 'Inverter', 'Battery', 'Battery'],\n",
    "    'Price': ['250', '500', '300', '450'],\n",
    "    'Quantity': ['10', '5', '8', '7']\n",
    "}\n",
    "df_types = pd.DataFrame(data)\n",
    "print(\"DataFrame with Incorrect Data Types:\")\n",
    "print(df_types.dtypes)\n",
    "\n",
    "# Correcting data types\n",
    "df_types['OrderID'] = df_types['OrderID'].astype(int)\n",
    "df_types['Price'] = df_types['Price'].astype(float)\n",
    "df_types['Quantity'] = df_types['Quantity'].astype(int)\n",
    "\n",
    "print(\"\\nDataFrame after Correcting Data Types:\")\n",
    "print(df_types.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to Handle Outliers/Inconsistent Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with Outliers:\n",
      "   Sales\n",
      "0    100\n",
      "1    150\n",
      "2    200\n",
      "3    250\n",
      "4    300\n",
      "5   1000\n",
      "6    350\n",
      "7    400\n",
      "\n",
      "DataFrame with Z-Scores:\n",
      "   Sales   Z_Score\n",
      "0    100 -0.919494\n",
      "1    150 -0.730880\n",
      "2    200 -0.542266\n",
      "3    250 -0.353652\n",
      "4    300 -0.165037\n",
      "5   1000  2.475561\n",
      "6    350  0.023577\n",
      "7    400  0.212191\n",
      "\n",
      "DataFrame after Removing Outliers:\n",
      "   Sales   Z_Score\n",
      "2    200 -0.542266\n",
      "3    250 -0.353652\n",
      "4    300 -0.165037\n",
      "6    350  0.023577\n",
      "7    400  0.212191\n"
     ]
    }
   ],
   "source": [
    "# How to Handle Outliers/Inconsistent Data\n",
    "# Sample DataFrame with outliers\n",
    "data = {\n",
    "    'Sales': [100, 150, 200, 250, 300, 1000, 350, 400]\n",
    "}\n",
    "df_outliers = pd.DataFrame(data)\n",
    "\n",
    "print(\"DataFrame with Outliers:\")\n",
    "print(df_outliers)\n",
    "\n",
    "# Detecting outliers using Z-score\n",
    "from scipy import stats\n",
    "\n",
    "df_outliers['Z_Score'] = stats.zscore(df_outliers['Sales'])\n",
    "print(\"\\nDataFrame with Z-Scores:\")\n",
    "print(df_outliers)\n",
    "\n",
    "# Removing outliers with Z-score > 2, or < -2, but you can choose the threshold\n",
    "df_no_outliers = df_outliers[abs(df_outliers['Z_Score']) < 2]\n",
    "print(\"\\nDataFrame after Removing Outliers:\")\n",
    "print(df_no_outliers.tail())\n",
    "\n",
    "# In this case, we removed the Sale of 1000 as it was considered an outlier based on the Z-score.\n",
    "# It's important to carefully consider the context of the data and the impact of removing outliers on the analysis.\n",
    "# Outliers may contain valuable information or indicate errors in the data collection process.\n",
    "# Again, as said a few times previously, document and communicate the criteria used to detect and remove outliers.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
